# 简介 Introduction

`Apache Kafka®`是一个分布式流平台。这到底是什么意思呢？

流平台具有三个关键功能：

* 发布和订阅记录数据记录流，类似于消息队列或企业消息传递系统
* 以持久的且具有容错能力的方式存储数据记录流
* 处理数据记录流

`Kafka`通常用于两大类应用程序：

* 建立实时的流数据管道，使系统或应用程序之间能够可靠地获取数据
* 建立实时的流应用程序，可以转换或响应数据流

为了理解`Kafka`如何完成这些事，让我们从头开始深入探索`Kafka`的功能。

首先了解几个概念：

* `Kafka`是在一个或多个可以跨越多个数据中心的服务器上以集群方式运行
* `Kafka`集群以`topics`归类储存的数据记录流
* 每条数据记录由一个键、一个值和一个时间戳构成

`Kafka`有四大核心`APIs`：

![1-1 &#x6838;&#x5FC3;APIs&#x793A;&#x610F;&#x56FE;](../.gitbook/assets/kafka-apis.png)

* [`Producer API`](../apis/producer-api.md)（生产者）允许应用程序发布数据记录流到一个或多个`topics`中
* [`Consumer API`](../apis/consumer-api.md)（消费者）允许应用程序订阅一个或多个`topics`并处理其生成的数据记录流
* [`Streams API`](../apis/streams-api/)（流处理）允许应用程序作为流处理器，消费从一个或多个`topics`中获取的输入流并生产输出流到一个或多个`topics`中，有效地进行输入流和输出流的转换
* [`Connector API`](../apis/connect-api.md)（连接器）允许建立和允许可复用的生产者和消费者，用来连接`topics`和已存在的应用程序或数据系统。例如关系型数据库的连接器可能会捕捉对表的所有更改

在`Kafka`中，服务端和客户端之间的通信是通过简单、高性能、无关编程语言的`TCP`协议来完成。该协议已经版本化，并维持对旧版本的向下兼容。我们提供`Java`版本的`Kafka`客户端，但客户端也同时支持[多种语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)。

## 主题和日志 Topics and Logs <a id="topics-n-logs"></a>

首先深入了解一个`Kafka`提供的数据记录流的核心抽象——**主题**\(**`topic`**\)

**主题**是数据记录发布的分类名称或订阅源名称。Kafka中的**主题**总是面向多订阅者的；也就是说一个主题可以拥有`0`个、`1`个或许多消费者来订阅写入该主题的数据。

对于每个主题，`Kafka`集群都会维护一个分区日志，其结构如下图所示：

![1-2 &#x4E3B;&#x9898;&#x5206;&#x533A;&#x65E5;&#x5FD7;&#x89E3;&#x6790;&#x56FE;](../.gitbook/assets/log_anatomy.png)

每个分区\(**`partition`**\)都是有序、不可变更的数据记录序列，数据记录可以持续地追加到结构化的提交日志中。分区中的数据记录都会被分配一个顺序生成的ID号，被称为偏移量\(**`offset`**\)，是每条数据记录在分区中的唯一识别标记。

`Kafka`集群会持久地保存所有发布的数据记录，不论其是否被消费使用，其保留期限是可以被配置的。例如如果保留策略设置为两天，那么一条数据记录发布后的两天之内是可以被消费的，之后会被丢弃以释放空间。`Kafka`的性能在不同数据大小情况下几乎是恒定的，因此长时间储存数据是没有问题的。

![1-3 &#x5206;&#x533A;&#x65E5;&#x5FD7;&#x793A;&#x610F;&#x56FE;](../.gitbook/assets/log_consumer.png)

事实上，每个消费者底层保留的唯一元数据是其在日志中的偏移量或位置。此偏移量是可以被消费者控制的：通常来说，消费者读取数据记录时会线性的向前移动其偏移量；但事实上，由于位置可以被消费者控制，那么就可以以想要的任意顺序消费这些数据记录。例如消费者可以重置到较早的偏移量以重新处理过往的数据，也可以跳到最新的数据记录位置并从“现在”开始消费记录。

这些功能的组合意味着`Kafka`消费者是非常轻便的，他们来去自如并且不会对集群或其他消费者产生太多影响。若你使用我们的命令行工具来监控任何topic的尾部内容，你并不会看到其他消费者消费数据时产生的变更。

日志的分区提供多种用途。首先，分区允许日志扩展到超出单个服务器所能容纳的大小。每个单独的分区必须适合承载它的服务器，但是一个主题可能有很多分区，因此它可以处理任意数量的数据。其次，分区可以作为并行的处理单元，more on that in a bit（不知道怎么翻）。

## 分布 distribution <a id="distribution"></a>

日志的分区分布在`Kafka`集群的服务器上，每个服务器处理数据并请求共享分区。每个分区都可以跨服务器复制，以实现容错功能。复制服务器的数量是可以配置的。

每个分区都有一个服务器作为`leader`（领导者），`0`个或多个服务器作为`followers`（追随者）。`leader`处理对分区的所有的读写请求，`followers`被动的复制`leader`。当`leader`服务器发生错误，`followers`中的一个会自动成为新的`leader`。每个服务器都可以作为一些分区的`leader`和其他分区的`followers`，因此集群的负载可以得到很好的平衡。

## 地理复制 Geo-Replication <a id="geo-replication"></a>

`Kafka MirrorMaker`为集群提供地理复制的支持。使用`MirrorMaker`，可以在多个数据中心或云区域中复制消息。您可以在主动/被动方案中使用它进行备份和恢复。或在主动/主动方案中将数据放置在离您的用户更近的位置，或支持数据位置要求。

## 生产者 Producers <a id="producers"></a>

生产者将数据发布到他们选择的主题。生产者负责选择将哪个数据记录分配给主题中的哪个分区。如果仅是为了平衡负载，可以以循环方式完成此操作；也可以根据某些语义分区功能（例如基于数据记录中的某些键）进行此操作。

## 消费者 Consumers <a id="consumers"></a>

消费者使用消费者组\(`consumer group`\)名来标记自己，发布到主题的每条数据记录都会被传递到每个消费者组中的一个实例。消费者实例可以在不同的进程中也可以在不同的机器中。

如果所有的实例标记为相同的消费者组，那么数据记录的传递会在这些消费者实例中有效地平衡负载。

如果所有的实例标记为不同的消费者组，那么每条数据记录都会被广播到所有的消费者进程中。

![1-4 &#x5206;&#x5E03;&#x5F0F;&#x6D88;&#x8D39;&#x8005;&#x7EC4;&#x793A;&#x610F;&#x56FE;](../.gitbook/assets/consumer-groups.png)

如图`1-4`一个双服务器的`Kafka`集群托管了含有两个消费者组的四个分区\(`P0`-`P3`\)。消费者组`A`含有两个消费者实例，消费者组`B`含有四个消费者实例。

然而更常见的是，我们发现主题只有少量的消费者组作为逻辑上的订阅者，每组都由许多消费者实例组成，以实现可伸缩性和容错能力。这无非就是发布-订阅\(`publish-subscribe`\)语义，其中订阅者是消费者的集群而不是单个进程。

在`Kafka`中实现消费的方式是通过在消费者实例上划分日志中的分区，以使得每个消费者实例在任何时间点都是分区的“公平份额”的独占消费者。`Kafka`协议动态处理了维护组成员身份的过程。如果新实例加入该组，它们将接管该组其他成员的某些分区；如果实例死亡，其负责的分区会被重新分配给其余实例。

`Kafka`仅提供分区中数据记录的总顺序，并不提供主题中不同分区之间的数据记录顺序。对大多数应用程序来说，按分区排序加上以键对数据进行分区的能力就已经足够了。然而如果你需要所有数据记录的总顺序，则可以使用只有一个分区的主题来实现，尽管这意味着每个消费者组只能有一个消费者实例。

## 多租户 Multi-tenancy <a id="multi-tenancy"></a>

你能够用多租户方案来部署`Kafka`。通过配置哪些主题能生产或消费数据来开启多租户模式。配额也会有运营支持。管理员可以在请求上定义和实施配额以控制客户端使用的代理资源。

更多信息可以查看[安全](../security/security-overview.md)章节。

## 保证 Guarantees <a id="guarantees"></a>

在较高级别上，`Kafka`可以提供如下保证：

* 由生产者发往特定主题分区的消息会按照其发送顺序添加。这意味着，如果记录`M1`是由于记录M2相同的生产者发送的，并且`M1`先被发送，那么`M1`将获得比`M2`更低的偏移量，并且在日志中也会更早出现。
* 消费者实例会按照储存在日志中的顺序查看数据记录。
* 对具有复制因子`N`的主题，我们最多可以容忍在`N-1`个服务器故障时仍然不会丢失任何提交给日志的数据记录。

更多信息可以查看[设计](../design/motivation.md)章节。

## 作为消息传递系统 Kafka as a Messaging System <a id="messaging-system"></a>

`Kafka`的流概念与传统的企业消息传递系统相比如何？

传统的消息传递有两种模型：队列和发布-订阅。在队列模型中，消费者池可以从服务器读取内容，并且每条记录都会传递到池中的一个消费者；在发布-订阅模型中，记录会被广播给所有的消费者。两种模型都有各自的优缺点。队列的优势在于它允许将数据的处理划分到多个消费者实例中，从而扩展处理量。不幸的是队列并不是多订阅者的模型，一旦进程读取了数据，数据就丢失了。发布-订阅可以广播数据到多个进程，但是因为每条消息都会发送给每个订阅者，所以无法做扩展处理。

`Kafka`中**消费者组**的概念汇总了这两个概念。与队列一样，消费者组允许将处理划分为一组进程（消费者组的成员）。与发布-订阅一样，`Kafka`允许广播消息到多个消费者组。

`Kafka`模型的优势在于每个主题兼具两种属性——可以扩展处理范围，也可以是多订阅者模式——不用必须在两者中选择其一。

与传统的消息传递系统相比，`Kafka`还具有更强的订购保证。

传统队列将数据记录按顺序保留在服务器上，如果有多个消费者从队列中消费，服务器将按照储存的顺序分发数据记录。然而尽管服务器按顺序分发记录，但是这些记录是异步的传递给消费者的，所以他们送达到不同消费者手中的顺序是错乱的。这实际上意味着在并行消费的情况下会丢失记录的顺序。消息传递系统通常通过“独占使用者”的概念来解决此问题，即仅允许一个进程从队列中消费，但是，这当然意味着在处理中没有并行性。

`Kafka`做得更好。通过主题中具有并行性（即分区）的概念，`Kafka`能够在消费者进程池中提供顺序保证和负载均衡。这是通过将主题中的分区分配给消费者组中的消费者来实现的，这使得每个分区会被组中的某个特定消费者完全消费。通过这样的方式确保了消费者仅仅是该分区的唯一读取器，并按照顺序消费数据。由于存在很多分区，因此这种做法也可以平衡许多消费者实例上的负载。但请注意，消费者组中的实例不能超过分区。

## 作为存储系统 Kafka as a Storage System <a id="storage-system"></a>

任何允许发布与消费无关的消息队列都有效地充当了运行中的消息存储系统。`Kafka`的不同之处在于它是一个非常好的存储系统。

写入`Kafka`中的数据将写入磁盘并复制以实现容错能力。`Kafka`允许生产者等待确认，因此直到数据被完全复制并保证即使服务器写入失败依然可以保留时才会被认为写入完成。

`Kafka`的磁盘结构可以进行很好的扩展。无论服务器上保留有50KB还是50TB的持久数据，`Kafka`都可以表现出同样的性能。

认真对待存储并允许客户端控制其读取位置的结果是，可以将`Kafka`视为一种专用于高性能、低延迟的提交日志存储、复制和传播的专用分布式文件系统。

更多信息可以查看[设计](../design/motivation.md)章节。

## 用于流处理 Kafka for Stream Processing <a id="stream-processing"></a>

仅读取，写入和存储数据流是不够的，`Kafka`的用途之一是实现对流的实时处理。

在`Kafka`中，流处理器是指从输入主题中获取连续数据流，对该输入进行一些处理并生成连续数据流以输出主题的总和。

例如，一个零售应用程序可以获取销售和运输的输入流并输出根据这些数据计算得出的重新订购和价格调整的流。

用生产者`API`和消费者`API`可以直接进行简单的数据处理。但是对于更复杂的转换，`Kafka`提供了非常综合的流处理`API`。这套`API`允许构建执行非重要处理的应用程序，这些应用程序可以计算流的聚合或将流连接在一起。

该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。

流处理`API`建立在`Kafka`提供的核心原语之上：其使用生产者`API`和消费者`API`进行输入，用`Kafka`进行状态存储，用同组机制来实现流处理器实例之间的容错。

## 将这些合在一起 Putting the Pieces Together <a id="together"></a>

将消息传递、存储和流处理结合在一起看上去并不寻常，但是这是对于`Kafka`作为流平台中的角色至关重要。

像`HDFS`这样的分布式文件系统运行存储静态文件以进行批处理。实际上，像这样的系统也可以存储和处理过去的历史数据。

传统的商业消息传递系统允许处理订阅之后传递来的“将来”的消息。用这种方式构建的应用程序会在将来的数据送达是进行处理。

`Kafka`将这两种特性结合，对于将`Kafka`用作流应用程序平台和流数据管道平台而言，这种结合至关重要。

通过结合存储和低延迟订阅，流应用程序可以以先相同的方式处理过去和将来的数据。也就是说一个单独的应用程序可以处理历史存储的数据，但并不是到最后一条记录为止，它可以继续处理将来送达的数据。这是流处理的通用概念，它包括了批处理以及消息驱动应用程序。

同样地，对于流数据管道，这种对实时事件订阅的组合使其可以将`Kafka`用于非常低延迟的管道，但是可靠的存储数据能力使其可以用于必须保证数据送达的关键数据，或用于仅定期加载数据或可能停机很长时间进行维护的脱机系统集成。流处理特性让数据送达时进行转换成为可能。

对于更多关于`Kafka`的信息，请继续阅读文档后续的章节。

\[test\]: [http://www.baidu.com](http://www.baidu.com)

